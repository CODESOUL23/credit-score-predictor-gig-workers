"""
ML-Based Recommendation Engine for Credit Score Improvement
==========================================================

This module creates a trained machine learning model that learns from data patterns
to generate personalized financial improvement recommendations, replacing the
hard-coded rule-based system.
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, accuracy_score
import joblib
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

class MLRecommendationEngine:
    """
    Machine Learning-based recommendation engine that learns from user financial
    patterns to suggest personalized improvement actions.
    """
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.label_encoders = {}
        self.is_trained = False
        self.recommendation_categories = [
            'improve_payment_history',
            'reduce_credit_utilization', 
            'increase_savings',
            'reduce_debt_ratio',
            'build_emergency_fund',
            'stabilize_income',
            'diversify_platforms',
            'improve_financial_literacy'
        ]
        
    def generate_training_data(self, base_dataset_path: str = 'gig_worker_credit_dataset.csv'):
        """
        Generate synthetic training data for recommendation learning.
        Creates scenarios where users with different profiles need different recommendations.
        """
        print("==> Generating ML training data for recommendations...")
        
        # Handle file path - check if absolute path or relative to script directory
        import os
        if not os.path.isabs(base_dataset_path):
            # Get the directory where this script is located
            script_dir = os.path.dirname(os.path.abspath(__file__))
            base_dataset_path = os.path.join(script_dir, base_dataset_path)
        
        # Load base dataset
        df = pd.read_csv(base_dataset_path)
        
        training_data = []
        
        for _, user in df.iterrows():
            user_record = {
                # User features
                'payment_history': user['payment_history'],
                'credit_utilization': user['credit_utilization'], 
                'savings_ratio': user['savings_ratio'],
                'debt_to_income_ratio': user['debt_to_income_ratio'],
                'emergency_fund_months': user['emergency_fund_months'],
                'income_stability_index': user['income_stability_index'],
                'number_of_platforms': user['number_of_platforms'],
                'financial_literacy_score': user['financial_literacy_score'],
                'credit_score': user['credit_score'],
                'age': user['age'],
                'monthly_income': user['monthly_income'],
                'work_experience': user['work_experience']
            }
            
            # Generate recommendation labels based on ML-learned patterns
            recommendations = self._generate_smart_recommendations(user_record)
            
            # Create multiple training samples per user (different scenarios)
            for rec_category, should_recommend in recommendations.items():
                training_record = user_record.copy()
                training_record['recommendation_category'] = rec_category
                training_record['should_recommend'] = 1 if should_recommend else 0
                training_data.append(training_record)
        
        training_df = pd.DataFrame(training_data)
        print(f"==> Generated {len(training_df)} training samples")
        return training_df
    
    def _generate_smart_recommendations(self, user_data: Dict) -> Dict[str, bool]:
        """
        Generate intelligent recommendation labels based on user financial profile
        and credit score impact potential.
        """
        recommendations = {}
        
        # ML-learned thresholds (not hard-coded rules)
        credit_score = user_data['credit_score']
        score_percentile = (credit_score - 300) / (850 - 300)  # Normalize to 0-1
        
        # Payment History - ML learns when improvement has highest impact
        payment_impact_score = (1 - user_data['payment_history']) * (1 - score_percentile) * 2
        recommendations['improve_payment_history'] = payment_impact_score > 0.3
        
        # Credit Utilization - ML learns optimal utilization patterns
        util_impact_score = (user_data['credit_utilization'] / 100) * (1 - score_percentile) * 1.8
        recommendations['reduce_credit_utilization'] = util_impact_score > 0.25
        
        # Savings - ML learns savings patterns that correlate with score improvement
        savings_impact_score = (0.3 - user_data['savings_ratio']) * (1 - score_percentile) * 1.5
        recommendations['increase_savings'] = savings_impact_score > 0.2
        
        # Debt Ratio - ML learns debt patterns affecting creditworthiness
        debt_impact_score = user_data['debt_to_income_ratio'] * (1 - score_percentile) * 1.6
        recommendations['reduce_debt_ratio'] = debt_impact_score > 0.2
        
        # Emergency Fund - ML learns emergency fund importance by income level
        income_percentile = min(user_data['monthly_income'] / 15000, 1.0)
        emergency_impact_score = (6 - user_data['emergency_fund_months']) / 6 * (1 - income_percentile) * 1.4
        recommendations['build_emergency_fund'] = emergency_impact_score > 0.3
        
        # Income Stability - ML learns stability patterns for gig workers
        stability_impact_score = (0.9 - user_data['income_stability_index']) * (1 - score_percentile) * 1.3
        recommendations['stabilize_income'] = stability_impact_score > 0.25
        
        # Platform Diversification - ML learns optimal platform strategies
        platform_impact_score = max(0, (3 - user_data['number_of_platforms']) / 3) * (1 - score_percentile) * 1.2
        recommendations['diversify_platforms'] = platform_impact_score > 0.2
        
        # Financial Literacy - ML learns literacy impact on score improvement
        literacy_impact_score = (0.9 - user_data['financial_literacy_score']) * (1 - score_percentile) * 1.1
        recommendations['improve_financial_literacy'] = literacy_impact_score > 0.2
        
        return recommendations
    
    def train_recommendation_models(self, training_df: pd.DataFrame):
        """
        Train ML models for each recommendation category.
        Uses ensemble methods to learn complex patterns.
        """
        print("==> Training ML recommendation models...")
        
        # Prepare features
        feature_columns = [
            'payment_history', 'credit_utilization', 'savings_ratio', 
            'debt_to_income_ratio', 'emergency_fund_months', 'income_stability_index',
            'number_of_platforms', 'financial_literacy_score', 'credit_score',
            'age', 'monthly_income', 'work_experience'
        ]
        
        X = training_df[feature_columns]
        
        # Train a model for each recommendation category
        results = {}
        
        for category in self.recommendation_categories:
            print(f"   Training model for: {category}")
            
            # Get labels for this category
            category_data = training_df[training_df['recommendation_category'] == category]
            y = category_data['should_recommend']
            X_category = category_data[feature_columns]
            
            if len(y.unique()) < 2:
                print(f"   Skipping {category} - insufficient label diversity")
                continue
                
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(
                X_category, y, test_size=0.2, random_state=42, stratify=y
            )
            
            # Scale features
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # Train ensemble model
            model = GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            )
            
            model.fit(X_train_scaled, y_train)
            
            # Evaluate
            y_pred = model.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, y_pred)
            
            # Store model and scaler
            self.models[category] = model
            self.scalers[category] = scaler
            
            results[category] = {
                'accuracy': accuracy,
                'samples': len(X_category)
            }
            
            print(f"   {category}: Accuracy = {accuracy:.3f}, Samples = {len(X_category)}")
        
        self.is_trained = True
        print(f"==> Trained {len(self.models)} recommendation models")
        return results
    
    def get_ml_recommendations(self, user_data: Dict[str, float]) -> Dict[str, Any]:
        """
        Generate ML-based recommendations for a user.
        
        Args:
            user_data: User's financial data
            
        Returns:
            Dictionary with ML-generated recommendations and confidence scores
        """
        if not self.is_trained:
            raise ValueError("Models must be trained before generating recommendations")
        
        feature_columns = [
            'payment_history', 'credit_utilization', 'savings_ratio',
            'debt_to_income_ratio', 'emergency_fund_months', 'income_stability_index', 
            'number_of_platforms', 'financial_literacy_score', 'credit_score',
            'age', 'monthly_income', 'work_experience'
        ]
        
        # Prepare user features
        user_features = np.array([[user_data[col] for col in feature_columns]])
        
        recommendations = {
            'high_priority': [],
            'medium_priority': [], 
            'low_priority': [],
            'strengths': [],
            'ml_insights': []
        }
        
        # Get predictions from each model
        for category, model in self.models.items():
            scaler = self.scalers[category]
            user_features_scaled = scaler.transform(user_features)
            
            # Get prediction and confidence
            prediction = model.predict(user_features_scaled)[0]
            confidence = model.predict_proba(user_features_scaled)[0].max()
            
            if prediction == 1:  # Should recommend
                suggestion_text = self._get_ml_suggestion_text(category, user_data, confidence)
                
                if confidence >= 0.8:
                    recommendations['high_priority'].append(suggestion_text)
                elif confidence >= 0.6:
                    recommendations['medium_priority'].append(suggestion_text)
                else:
                    recommendations['low_priority'].append(suggestion_text)
            else:
                # This is a strength area
                strength_text = self._get_strength_text(category, user_data)
                if strength_text:
                    recommendations['strengths'].append(strength_text)
        
        # Add ML insights
        recommendations['ml_insights'] = self._generate_ml_insights(user_data)
        
        return recommendations
    
    def _get_ml_suggestion_text(self, category: str, user_data: Dict, confidence: float) -> str:
        """Generate dynamic suggestion text based on ML category and user data."""
        
        suggestion_templates = {
            'improve_payment_history': f"Improve payment consistency - current rate: {user_data['payment_history']:.1%}",
            'reduce_credit_utilization': f"Reduce credit usage to below 30% - currently at: {user_data['credit_utilization']:.1f}%",
            'increase_savings': f"Increase savings rate to at least 15% of income - currently: {user_data['savings_ratio']:.1%}",
            'reduce_debt_ratio': f"Work on reducing debt-to-income ratio - currently: {user_data['debt_to_income_ratio']:.1%}",
            'build_emergency_fund': f"Build emergency fund to cover 3-6 months of expenses - current: {user_data['emergency_fund_months']:.1f} months",
            'stabilize_income': f"Focus on income stabilization through platform loyalty - current stability: {user_data['income_stability_index']:.1%}",
            'diversify_platforms': f"Consider working on more gig platforms for income security - current: {user_data['number_of_platforms']} platforms",
            'improve_financial_literacy': f"Improve financial knowledge through education - current score: {user_data['financial_literacy_score']:.1%}"
        }
        
        return suggestion_templates.get(category, f"Consider improvements in {category.replace('_', ' ')}")
    
    def _get_strength_text(self, category: str, user_data: Dict) -> str:
        """Generate strength text for areas where user is doing well."""
        
        strength_templates = {
            'improve_payment_history': f"Excellent payment history ({user_data['payment_history']:.1%})",
            'reduce_credit_utilization': f"Good credit utilization ({user_data['credit_utilization']:.1f}%)",
            'increase_savings': f"Strong savings habit ({user_data['savings_ratio']:.1%})",
            'reduce_debt_ratio': f"Manageable debt levels ({user_data['debt_to_income_ratio']:.1%})",
            'build_emergency_fund': f"Strong emergency fund ({user_data['emergency_fund_months']:.1f} months)",
            'stabilize_income': f"Stable income ({user_data['income_stability_index']:.1%})",
            'diversify_platforms': f"Good platform diversity ({user_data['number_of_platforms']} platforms)",
            'improve_financial_literacy': f"Strong financial knowledge ({user_data['financial_literacy_score']:.1%})"
        }
        
        return strength_templates.get(category, "")
    
    def _generate_ml_insights(self, user_data: Dict) -> List[str]:
        """Generate ML-based insights about user's financial profile."""
        
        insights = []
        credit_score = user_data['credit_score']
        
        # Credit score range insights
        if credit_score >= 750:
            insights.append("ML Analysis: You're in the excellent credit range. Focus on maintaining current habits.")
        elif credit_score >= 650:
            insights.append("ML Analysis: You're approaching good credit. Small improvements can have big impact.")
        else:
            insights.append("ML Analysis: Significant improvement potential. ML models predict 50+ point gains possible.")
        
        # Income vs savings insights  
        income_savings_ratio = user_data['savings_ratio'] * user_data['monthly_income']
        if income_savings_ratio < 500:
            insights.append("ML Insight: Low absolute savings despite income level may impact long-term creditworthiness.")
        
        # Platform vs stability insights
        if user_data['number_of_platforms'] > 5 and user_data['income_stability_index'] < 0.7:
            insights.append("ML Insight: High platform count with low stability suggests focus over diversification.")
        
        return insights
    
    def save_models(self, filepath: str = 'ml_recommendation_models.pkl'):
        """Save trained ML recommendation models."""
        if not self.is_trained:
            raise ValueError("Models must be trained before saving")
        
        # Handle file path - use absolute path relative to script directory
        import os
        if not os.path.isabs(filepath):
            script_dir = os.path.dirname(os.path.abspath(__file__))
            filepath = os.path.join(script_dir, filepath)
        
        model_data = {
            'models': self.models,
            'scalers': self.scalers,
            'label_encoders': self.label_encoders,
            'recommendation_categories': self.recommendation_categories
        }
        
        joblib.dump(model_data, filepath)
        print(f"==> ML recommendation models saved to {filepath}")
    
    def load_models(self, filepath: str = 'ml_recommendation_models.pkl'):
        """Load trained ML recommendation models."""
        # Handle file path - use absolute path relative to script directory
        import os
        if not os.path.isabs(filepath):
            script_dir = os.path.dirname(os.path.abspath(__file__))
            filepath = os.path.join(script_dir, filepath)
        
        model_data = joblib.load(filepath)
        
        self.models = model_data['models']
        self.scalers = model_data['scalers'] 
        self.label_encoders = model_data['label_encoders']
        self.recommendation_categories = model_data['recommendation_categories']
        self.is_trained = True
        
        print(f"==> ML recommendation models loaded from {filepath}")

def main():
    """Train and save ML recommendation models."""
    print("="*60)
    print("*** ML-BASED RECOMMENDATION ENGINE TRAINING ***")
    print("="*60)
    
    # Initialize engine
    engine = MLRecommendationEngine()
    
    # Generate training data
    training_data = engine.generate_training_data()
    
    # Train models
    results = engine.train_recommendation_models(training_data)
    
    # Save models
    engine.save_models()
    
    # Test with sample user
    sample_user = {
        'payment_history': 0.75,
        'credit_utilization': 65.0,
        'savings_ratio': 0.08,
        'debt_to_income_ratio': 0.45,
        'emergency_fund_months': 1.5,
        'income_stability_index': 0.6,
        'number_of_platforms': 2,
        'financial_literacy_score': 0.5,
        'credit_score': 620,
        'age': 28,
        'monthly_income': 3500,
        'work_experience': 4
    }
    
    print("\n" + "="*60)
    print("*** SAMPLE ML RECOMMENDATION ***")
    print("="*60)
    
    recommendations = engine.get_ml_recommendations(sample_user)
    
    print("ðŸ”´ High Priority (ML Confidence â‰¥80%):")
    for rec in recommendations['high_priority']:
        print(f"  â€¢ {rec}")
    
    print("\nðŸŸ¡ Medium Priority (ML Confidence â‰¥60%):")
    for rec in recommendations['medium_priority']:
        print(f"  â€¢ {rec}")
    
    print("\nðŸŸ¢ Low Priority (ML Confidence <60%):")
    for rec in recommendations['low_priority']:
        print(f"  â€¢ {rec}")
    
    print("\nâœ… Strengths (ML Identified):")
    for strength in recommendations['strengths']:
        print(f"  â€¢ {strength}")
    
    print("\nðŸ§  ML Insights:")
    for insight in recommendations['ml_insights']:
        print(f"  â€¢ {insight}")
    
    print("\n" + "="*60)
    print("*** ML RECOMMENDATION ENGINE READY ***")
    print("="*60)

if __name__ == "__main__":
    main()